{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an implementation of the iLPD method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "import tensorboardX\n",
    "import memcnn\n",
    "\n",
    "import odl\n",
    "from odl.contrib import fom\n",
    "from odl.contrib import torch as odl_torch\n",
    "\n",
    "from mayo_generator import generate_mayo\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "name = 'invertible'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ODL data structures to define the Ray Transform operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 512\n",
    "xlim = 128\n",
    "space = odl.uniform_discr([-xlim]*2, [xlim]*2, [size]*2, dtype='float32')\n",
    "angle_partition = odl.uniform_partition(0, 2 * np.pi, 1000)\n",
    "detector_partition = odl.uniform_partition(-360, 360, 1000)\n",
    "geometry = odl.tomo.FanBeamGeometry(angle_partition, detector_partition,src_radius=500, det_radius=500)\n",
    "operator = odl.tomo.RayTransform(space, geometry)\n",
    "\n",
    "# transform the operator and it's adjoint into pytorch modules\n",
    "pt_op = odl_torch.OperatorModule(operator)\n",
    "pt_op_adj = odl_torch.OperatorModule(operator.adjoint)\n",
    "\n",
    "# after each application of the operator, divide the result by it's norm\n",
    "# for numerical stability\n",
    "opnorm = operator.norm(estimate=True)\n",
    "print(\"Norm of the operator:\", opnorm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp = 10000 # number of photons per pixel determines the amount of noise in the projection data\n",
    "\n",
    "# create test and validation images once, after that load from disk\n",
    "if not os.path.exists('test_image_full_noisy.npy'):\n",
    "    test_image, test_data = generate_mayo(operator, 'test', 210, photons_per_pixel=ppp).__next__()\n",
    "    np.save(\"test_image_full_noisy.npy\", test_image)\n",
    "    np.save(\"test_data_full_noisy.npy\", test_data)\n",
    "\n",
    "val_ration = 0.01\n",
    "if not os.path.exists('val_image_full_noisy.npy'):\n",
    "    val_image, val_data = generate_mayo(operator, 'validate', 21, val_ration, photons_per_pixel=ppp).__next__()\n",
    "    np.save(\"val_image_full_noisy.npy\", val_image)\n",
    "    np.save(\"val_data_full_noisy.npy\", val_data)\n",
    "\n",
    "val_image = np.load(\"val_image_full_noisy.npy\")\n",
    "val_data = np.load(\"val_data_full_noisy.npy\")\n",
    "val_image_pt = torch.from_numpy(val_image).type(dtype)\n",
    "val_data_pt = torch.from_numpy(val_data).type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the iLPD architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 1 # batch size\n",
    "n_iter = 20 # number of unrolled iterations\n",
    "# number of primal and dual memory channels\n",
    "n_primal = 1 \n",
    "n_dual = 1\n",
    "\n",
    "\n",
    "class Iteration(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.op = pt_op\n",
    "        self.op_adj = pt_op_adj\n",
    "        self.filters = 32\n",
    "\n",
    "        self.primalblock = nn.Sequential(\n",
    "            nn.Conv2d(n_primal, self.filters, 3, padding=1),\n",
    "            nn.PReLU(num_parameters=self.filters, init=0.0),\n",
    "            nn.Conv2d(self.filters, self.filters, 3, padding=1),\n",
    "            nn.PReLU(num_parameters=self.filters, init=0.0),\n",
    "            nn.Conv2d(self.filters, n_primal, 3, padding=1))\n",
    "        \n",
    "        self.dualblock = nn.Sequential(\n",
    "            nn.Conv2d(n_dual + 1, self.filters, 3, padding=1),\n",
    "            nn.PReLU(num_parameters=self.filters, init=0.0),\n",
    "            nn.Conv2d(self.filters, self.filters, 3, padding=1),\n",
    "            nn.PReLU(num_parameters=self.filters, init=0.0),\n",
    "            nn.Conv2d(self.filters, n_dual, 3, padding=1))\n",
    "            \n",
    "\n",
    "    def forward(self, primal, dual, y):\n",
    "        \n",
    "        # dual block\n",
    "        evalop = self.op(primal) / opnorm\n",
    "        inp = torch.cat([evalop, y / opnorm ], dim=1)\n",
    "        dual = dual + self.dualblock(inp)\n",
    "        \n",
    "        # primal block\n",
    "        evalop = self.op_adj(dual) / opnorm\n",
    "        inp = evalop\n",
    "        primal = primal + self.primalblock(inp)\n",
    "\n",
    "        return primal, dual, y\n",
    "    \n",
    "    \n",
    "    def inverse(self, primal, dual, y):\n",
    "        \n",
    "        # primal block\n",
    "        evalop = self.op_adj(dual) / opnorm\n",
    "        inp = evalop\n",
    "        primal = primal - self.primalblock(inp)\n",
    "        \n",
    "        # dual block\n",
    "        evalop = self.op(primal) / opnorm\n",
    "        inp = torch.cat([evalop, y / opnorm ], dim=1)\n",
    "        dual = dual - self.dualblock(inp)\n",
    "        return primal, dual, y\n",
    "    \n",
    "class IterativeNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            iteration = Iteration()\n",
    "            inv_iteration = memcnn.InvertibleModuleWrapper(fn=iteration,\n",
    "                                                           keep_input=True, \n",
    "                                                           keep_input_inverse=True)\n",
    "            setattr(self, 'iteration_{}'.format(i), inv_iteration)\n",
    "\n",
    "    def forward(self, y, true):\n",
    "        im_shape = true.shape[2:]\n",
    "        data_shape = y.shape[2:]\n",
    "        primal = torch.zeros((n_data, n_primal) + im_shape).type(dtype)\n",
    "        dual = torch.zeros((n_data, n_dual) + data_shape).type(dtype)\n",
    "        \n",
    "        for i in range(n_iter):\n",
    "            iteration = getattr(self, 'iteration_{}'.format(i))\n",
    "            primal, dual, y = iteration(primal, dual, y)\n",
    "        \n",
    "        res = primal[:, 0:1, ...]\n",
    "        loss = self.loss(res, true)\n",
    "            \n",
    "        return res, loss\n",
    "    \n",
    "    def inv_module_eval(self):\n",
    "        for i in range(n_iter):\n",
    "            iteration = getattr(self, 'iteration_{}'.format(i))\n",
    "            iteration.num_bwd_passes = 0 # number of backward passes\n",
    "            iteration.eval()\n",
    "            \n",
    "    def inv_module_train(self):\n",
    "        for i in range(n_iter):\n",
    "            iteration = getattr(self, 'iteration_{}'.format(i))\n",
    "            iteration.num_bwd_passes = 1 # number of backward passes\n",
    "            iteration.train()\n",
    "\n",
    "# This is \"Xavier\" initialization of weights.\n",
    "# It is very important for the training!!!\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        shape = m.weight.shape\n",
    "        lim = np.sqrt(6/(shape[0] + shape[1])/shape[2]/shape[3])\n",
    "        m.weight.data.uniform_(-lim, lim)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "iter_net = IterativeNetwork().type(dtype)\n",
    "iter_net.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define summary functions to view logs in the tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_image(writer, name, image, it):\n",
    "    image = image[0,0]\n",
    "    image = (image - torch.min(image)) / (torch.max(image) - torch.min(image) + 1e-5)\n",
    "    writer.add_image(name, image, it, dataformats='HW')\n",
    "        \n",
    "def summaries(writer, result, true, loss, it, do_print=False):\n",
    "    residual = result - true \n",
    "    squared_error = residual ** 2\n",
    "    mse = torch.mean(squared_error)\n",
    "    maxval = torch.max(true) - torch.min(true)\n",
    "    psnr = 20 * torch.log10(maxval) -10 * torch.log10(mse)\n",
    "    \n",
    "    if do_print:\n",
    "        print(it, mse.item(), psnr.item())\n",
    "\n",
    "    writer.add_scalar('loss', loss, it)\n",
    "    writer.add_scalar('psnr', psnr, it)\n",
    "\n",
    "    summary_image(writer, 'result', result, it)\n",
    "    #summary_image(writer, 'true', true, it)\n",
    "\n",
    "train_writer = tensorboardX.SummaryWriter(comment=\"/train_\"+name)\n",
    "test_writer = tensorboardX.SummaryWriter(comment=\"/test_\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_steps = 100001\n",
    "starter_learning_rate = 0.5 * 1e-3\n",
    "optimizer = torch.optim.Adam(iter_net.parameters(), lr=starter_learning_rate, betas=(0.9, 0.99))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, maximum_steps)\n",
    "\n",
    "train_generator = generate_mayo(operator, 'train', n_data, val_ration, photons_per_pixel=ppp)\n",
    "\n",
    "for i in range(maximum_steps):\n",
    "    iter_net.train()\n",
    "    iter_net.inv_module_train()\n",
    "    if i%10 == 0:\n",
    "        x_true, y = train_generator.__next__() \n",
    "        x_true_pt = torch.from_numpy(x_true).type(dtype)\n",
    "        y_pt = torch.from_numpy(y).type(dtype)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output, loss = iter_net(y_pt, x_true_pt)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(iter_net.parameters(), max_norm=1.0, norm_type=2)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        summaries(train_writer, output, x_true_pt, loss, i, do_print=False)\n",
    "    if i % 100 == 0:\n",
    "        iter_net.eval()\n",
    "        iter_net.inv_module_eval()\n",
    "        output_test, loss_test = iter_net(val_data_pt[0:1], val_image_pt[0:1])\n",
    "        summaries(test_writer, output_test, val_image_pt[0:1], loss_test, i, do_print=True)\n",
    "        \n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        torch.save(iter_net.state_dict(), name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_net.load_state_dict(torch.load(name))\n",
    "iter_net.eval()\n",
    "iter_net.inv_module_eval()\n",
    "\n",
    "test_image = np.load(\"test_image_full_noisy.npy\")\n",
    "test_data = np.load(\"test_data_full_noisy.npy\")\n",
    "test_image_pt = torch.from_numpy(test_image).type(dtype)\n",
    "test_data_pt = torch.from_numpy(test_data).type(dtype)\n",
    "\n",
    "def evaluate(test_image, test_data, plot=False):\n",
    "    \n",
    "    result, loss = iter_net(test_data, test_image)\n",
    "    result = result.detach().cpu().numpy()\n",
    "    true = test_image.detach().cpu().numpy()\n",
    "    \n",
    "    names = [\"True\", \"iLPD\"]\n",
    "    \n",
    "    if plot:\n",
    "        figsize = 10\n",
    "        fig, row = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(2*figsize, figsize))\n",
    "        for name, res, ax in zip(names, [true, result], row):\n",
    "            ax.set_title(name)\n",
    "            ax.imshow(res.squeeze(), clim = [0.8, 1.2], cmap=\"bone\")\n",
    "            ax.set_axis_off()\n",
    "        plt.show()\n",
    "        \n",
    "    return result\n",
    "\n",
    "# evaluate the method slice by slice\n",
    "res = []\n",
    "for i in range(test_image_pt.shape[0]):\n",
    "    r = evaluate(test_image_pt[i:(i+1)], test_data_pt[i:(i+1)])\n",
    "    res.append(r)\n",
    "res = np.stack(res, axis=1)[0]\n",
    "l1 = fom.mean_squared_error(res, test_image)\n",
    "l2 = fom.psnr(res, test_image)\n",
    "l3 = fom.ssim(res, test_image)\n",
    "print('Final result. Mean squared error: {}, PSNR: {}, SSIM: {}'.format(l1, l2, l3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
